{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m\n",
    "from preprocessing import *\n",
    "from plots import *\n",
    "from crossval import *\n",
    "from stochlogreg import *\n",
    "from split_data import *\n",
    "from classification_accuracy import *\n",
    "from helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "DATA_TRAIN_PATH = 'C:/Users/joeld/Desktop/EPFL/machine learning/AIAIaie/data/train.csv' # TODO: download train data and supply path here \n",
    "#DATA_TRAIN_PATH = '/Users/benoithohl/Desktop/epfl/master_epfl/Ma3/Machine_learning/AIAIaie/data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "      <th>DER_lep_eta_centrality</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>s</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.910</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>197.760</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.396</td>\n",
       "      <td>0.200</td>\n",
       "      <td>32.638</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.381</td>\n",
       "      <td>51.626</td>\n",
       "      <td>2.273</td>\n",
       "      <td>-2.414</td>\n",
       "      <td>16.824</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>b</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>125.157</td>\n",
       "      <td>0.879</td>\n",
       "      <td>1.414</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>42.014</td>\n",
       "      <td>2.039</td>\n",
       "      <td>-3.011</td>\n",
       "      <td>36.918</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.103</td>\n",
       "      <td>44.704</td>\n",
       "      <td>-1.916</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>197.814</td>\n",
       "      <td>3.776</td>\n",
       "      <td>1.414</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>32.154</td>\n",
       "      <td>-0.705</td>\n",
       "      <td>-2.093</td>\n",
       "      <td>121.409</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>1.052</td>\n",
       "      <td>54.283</td>\n",
       "      <td>-2.186</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>b</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>75.968</td>\n",
       "      <td>2.354</td>\n",
       "      <td>-1.285</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>22.647</td>\n",
       "      <td>-1.655</td>\n",
       "      <td>0.010</td>\n",
       "      <td>53.321</td>\n",
       "      <td>-0.522</td>\n",
       "      <td>-3.100</td>\n",
       "      <td>31.082</td>\n",
       "      <td>0.060</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>b</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>57.983</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-1.385</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>28.209</td>\n",
       "      <td>-2.197</td>\n",
       "      <td>-2.231</td>\n",
       "      <td>29.774</td>\n",
       "      <td>0.798</td>\n",
       "      <td>1.569</td>\n",
       "      <td>2.723</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100005</td>\n",
       "      <td>b</td>\n",
       "      <td>89.744</td>\n",
       "      <td>13.550</td>\n",
       "      <td>59.149</td>\n",
       "      <td>116.344</td>\n",
       "      <td>2.636</td>\n",
       "      <td>284.584</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>1.362</td>\n",
       "      <td>61.619</td>\n",
       "      <td>278.876</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.975</td>\n",
       "      <td>53.651</td>\n",
       "      <td>0.371</td>\n",
       "      <td>1.329</td>\n",
       "      <td>31.565</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>1.857</td>\n",
       "      <td>40.735</td>\n",
       "      <td>2.237</td>\n",
       "      <td>282.849</td>\n",
       "      <td>3</td>\n",
       "      <td>90.547</td>\n",
       "      <td>-2.412</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>56.165</td>\n",
       "      <td>0.224</td>\n",
       "      <td>3.106</td>\n",
       "      <td>193.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100006</td>\n",
       "      <td>s</td>\n",
       "      <td>148.754</td>\n",
       "      <td>28.862</td>\n",
       "      <td>107.782</td>\n",
       "      <td>106.130</td>\n",
       "      <td>0.733</td>\n",
       "      <td>158.359</td>\n",
       "      <td>0.113</td>\n",
       "      <td>2.941</td>\n",
       "      <td>2.545</td>\n",
       "      <td>305.967</td>\n",
       "      <td>3.371</td>\n",
       "      <td>1.393</td>\n",
       "      <td>0.791</td>\n",
       "      <td>28.850</td>\n",
       "      <td>1.113</td>\n",
       "      <td>2.409</td>\n",
       "      <td>97.240</td>\n",
       "      <td>0.675</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>38.421</td>\n",
       "      <td>-1.443</td>\n",
       "      <td>294.074</td>\n",
       "      <td>2</td>\n",
       "      <td>123.010</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.450</td>\n",
       "      <td>56.867</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>179.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100007</td>\n",
       "      <td>s</td>\n",
       "      <td>154.916</td>\n",
       "      <td>10.418</td>\n",
       "      <td>94.714</td>\n",
       "      <td>29.169</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.897</td>\n",
       "      <td>1.526</td>\n",
       "      <td>138.178</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-1.305</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>78.800</td>\n",
       "      <td>0.654</td>\n",
       "      <td>1.547</td>\n",
       "      <td>28.740</td>\n",
       "      <td>0.506</td>\n",
       "      <td>-1.347</td>\n",
       "      <td>22.275</td>\n",
       "      <td>-1.761</td>\n",
       "      <td>187.299</td>\n",
       "      <td>1</td>\n",
       "      <td>30.638</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>-1.724</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>30.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100008</td>\n",
       "      <td>b</td>\n",
       "      <td>105.594</td>\n",
       "      <td>50.559</td>\n",
       "      <td>100.989</td>\n",
       "      <td>4.288</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.904</td>\n",
       "      <td>4.288</td>\n",
       "      <td>65.333</td>\n",
       "      <td>0.675</td>\n",
       "      <td>-1.366</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>39.008</td>\n",
       "      <td>2.433</td>\n",
       "      <td>-2.532</td>\n",
       "      <td>26.325</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1.884</td>\n",
       "      <td>37.791</td>\n",
       "      <td>0.024</td>\n",
       "      <td>129.804</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100009</td>\n",
       "      <td>s</td>\n",
       "      <td>128.053</td>\n",
       "      <td>88.941</td>\n",
       "      <td>69.272</td>\n",
       "      <td>193.392</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>28.859</td>\n",
       "      <td>255.123</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>54.646</td>\n",
       "      <td>-1.533</td>\n",
       "      <td>0.416</td>\n",
       "      <td>32.742</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>132.678</td>\n",
       "      <td>0.845</td>\n",
       "      <td>294.741</td>\n",
       "      <td>1</td>\n",
       "      <td>167.735</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>-2.514</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>167.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100010</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>86.240</td>\n",
       "      <td>79.692</td>\n",
       "      <td>27.201</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.338</td>\n",
       "      <td>27.201</td>\n",
       "      <td>81.734</td>\n",
       "      <td>1.750</td>\n",
       "      <td>-1.412</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>29.718</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>2.878</td>\n",
       "      <td>52.016</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-1.288</td>\n",
       "      <td>51.276</td>\n",
       "      <td>0.688</td>\n",
       "      <td>250.178</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100011</td>\n",
       "      <td>b</td>\n",
       "      <td>114.744</td>\n",
       "      <td>10.286</td>\n",
       "      <td>75.712</td>\n",
       "      <td>30.816</td>\n",
       "      <td>2.563</td>\n",
       "      <td>252.599</td>\n",
       "      <td>-1.401</td>\n",
       "      <td>2.888</td>\n",
       "      <td>36.745</td>\n",
       "      <td>239.804</td>\n",
       "      <td>1.061</td>\n",
       "      <td>1.364</td>\n",
       "      <td>0.769</td>\n",
       "      <td>35.976</td>\n",
       "      <td>-0.669</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>38.188</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>2.502</td>\n",
       "      <td>22.385</td>\n",
       "      <td>2.148</td>\n",
       "      <td>290.547</td>\n",
       "      <td>3</td>\n",
       "      <td>76.773</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>0.303</td>\n",
       "      <td>56.876</td>\n",
       "      <td>1.773</td>\n",
       "      <td>-2.079</td>\n",
       "      <td>165.640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id Prediction  DER_mass_MMC  DER_mass_transverse_met_lep  \\\n",
       "0   100000          s       138.470                       51.655   \n",
       "1   100001          b       160.937                       68.768   \n",
       "2   100002          b      -999.000                      162.172   \n",
       "3   100003          b       143.905                       81.417   \n",
       "4   100004          b       175.864                       16.915   \n",
       "5   100005          b        89.744                       13.550   \n",
       "6   100006          s       148.754                       28.862   \n",
       "7   100007          s       154.916                       10.418   \n",
       "8   100008          b       105.594                       50.559   \n",
       "9   100009          s       128.053                       88.941   \n",
       "10  100010          b      -999.000                       86.240   \n",
       "11  100011          b       114.744                       10.286   \n",
       "\n",
       "    DER_mass_vis  DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "0         97.827    27.980                 0.910           124.711   \n",
       "1        103.235    48.146              -999.000          -999.000   \n",
       "2        125.953    35.635              -999.000          -999.000   \n",
       "3         80.943     0.414              -999.000          -999.000   \n",
       "4        134.805    16.405              -999.000          -999.000   \n",
       "5         59.149   116.344                 2.636           284.584   \n",
       "6        107.782   106.130                 0.733           158.359   \n",
       "7         94.714    29.169              -999.000          -999.000   \n",
       "8        100.989     4.288              -999.000          -999.000   \n",
       "9         69.272   193.392              -999.000          -999.000   \n",
       "10        79.692    27.201              -999.000          -999.000   \n",
       "11        75.712    30.816                 2.563           252.599   \n",
       "\n",
       "    DER_prodeta_jet_jet  DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  \\\n",
       "0                 2.666               3.064      41.928     197.760   \n",
       "1              -999.000               3.473       2.078     125.157   \n",
       "2              -999.000               3.148       9.336     197.814   \n",
       "3              -999.000               3.310       0.414      75.968   \n",
       "4              -999.000               3.891      16.405      57.983   \n",
       "5                -0.540               1.362      61.619     278.876   \n",
       "6                 0.113               2.941       2.545     305.967   \n",
       "7              -999.000               2.897       1.526     138.178   \n",
       "8              -999.000               2.904       4.288      65.333   \n",
       "9              -999.000               1.609      28.859     255.123   \n",
       "10             -999.000               2.338      27.201      81.734   \n",
       "11               -1.401               2.888      36.745     239.804   \n",
       "\n",
       "    DER_pt_ratio_lep_tau  DER_met_phi_centrality  DER_lep_eta_centrality  \\\n",
       "0                  1.582                   1.396                   0.200   \n",
       "1                  0.879                   1.414                -999.000   \n",
       "2                  3.776                   1.414                -999.000   \n",
       "3                  2.354                  -1.285                -999.000   \n",
       "4                  1.056                  -1.385                -999.000   \n",
       "5                  0.588                   0.479                   0.975   \n",
       "6                  3.371                   1.393                   0.791   \n",
       "7                  0.365                  -1.305                -999.000   \n",
       "8                  0.675                  -1.366                -999.000   \n",
       "9                  0.599                   0.538                -999.000   \n",
       "10                 1.750                  -1.412                -999.000   \n",
       "11                 1.061                   1.364                   0.769   \n",
       "\n",
       "    PRI_tau_pt  PRI_tau_eta  PRI_tau_phi  PRI_lep_pt  PRI_lep_eta  \\\n",
       "0       32.638        1.017        0.381      51.626        2.273   \n",
       "1       42.014        2.039       -3.011      36.918        0.501   \n",
       "2       32.154       -0.705       -2.093     121.409       -0.953   \n",
       "3       22.647       -1.655        0.010      53.321       -0.522   \n",
       "4       28.209       -2.197       -2.231      29.774        0.798   \n",
       "5       53.651        0.371        1.329      31.565       -0.884   \n",
       "6       28.850        1.113        2.409      97.240        0.675   \n",
       "7       78.800        0.654        1.547      28.740        0.506   \n",
       "8       39.008        2.433       -2.532      26.325        0.210   \n",
       "9       54.646       -1.533        0.416      32.742       -0.317   \n",
       "10      29.718       -0.866        2.878      52.016        0.126   \n",
       "11      35.976       -0.669       -0.342      38.188       -0.165   \n",
       "\n",
       "    PRI_lep_phi  PRI_met  PRI_met_phi  PRI_met_sumet  PRI_jet_num  \\\n",
       "0        -2.414   16.824       -0.277        258.733            2   \n",
       "1         0.103   44.704       -1.916        164.546            1   \n",
       "2         1.052   54.283       -2.186        260.414            1   \n",
       "3        -3.100   31.082        0.060         86.062            0   \n",
       "4         1.569    2.723       -0.871         53.131            0   \n",
       "5         1.857   40.735        2.237        282.849            3   \n",
       "6        -0.966   38.421       -1.443        294.074            2   \n",
       "7        -1.347   22.275       -1.761        187.299            1   \n",
       "8         1.884   37.791        0.024        129.804            0   \n",
       "9        -0.636  132.678        0.845        294.741            1   \n",
       "10       -1.288   51.276        0.688        250.178            0   \n",
       "11        2.502   22.385        2.148        290.547            3   \n",
       "\n",
       "    PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "0               67.435                2.150                0.444   \n",
       "1               46.226                0.725                1.158   \n",
       "2               44.251                2.053               -2.028   \n",
       "3             -999.000             -999.000             -999.000   \n",
       "4             -999.000             -999.000             -999.000   \n",
       "5               90.547               -2.412               -0.653   \n",
       "6              123.010                0.864                1.450   \n",
       "7               30.638               -0.715               -1.724   \n",
       "8             -999.000             -999.000             -999.000   \n",
       "9              167.735               -2.767               -2.514   \n",
       "10            -999.000             -999.000             -999.000   \n",
       "11              76.773               -0.790                0.303   \n",
       "\n",
       "    PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "0                  46.062                   1.240                  -2.475   \n",
       "1                -999.000                -999.000                -999.000   \n",
       "2                -999.000                -999.000                -999.000   \n",
       "3                -999.000                -999.000                -999.000   \n",
       "4                -999.000                -999.000                -999.000   \n",
       "5                  56.165                   0.224                   3.106   \n",
       "6                  56.867                   0.131                  -2.767   \n",
       "7                -999.000                -999.000                -999.000   \n",
       "8                -999.000                -999.000                -999.000   \n",
       "9                -999.000                -999.000                -999.000   \n",
       "10               -999.000                -999.000                -999.000   \n",
       "11                 56.876                   1.773                  -2.079   \n",
       "\n",
       "    PRI_jet_all_pt  \n",
       "0          113.497  \n",
       "1           46.226  \n",
       "2           44.251  \n",
       "3            0.000  \n",
       "4            0.000  \n",
       "5          193.660  \n",
       "6          179.877  \n",
       "7           30.638  \n",
       "8            0.000  \n",
       "9          167.735  \n",
       "10           0.000  \n",
       "11         165.640  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_TRAIN_PATH)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "data.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data tX:  (250000, 30)\n",
      "**\n",
      "250000\n",
      "[ 138.47   160.937 -999.     143.905  175.864   89.744  148.754  154.916\n",
      "  105.594  128.053 -999.     114.744  145.297   82.488 -999.     111.026\n",
      "  114.256  127.861 -999.    -999.    -999.      90.736   87.075  141.481\n",
      "  110.785   76.883  137.197  111.271  118.104   98.761]\n",
      "**\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of data tX: \",tX.shape)\n",
    "print(\"**\")\n",
    "print(len(tX[:,1]))\n",
    "\n",
    "print(tX[0:30,0])\n",
    "print(\"**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 features removed (features number:  [ 4  5  6 12 26 27 28] )\n",
      "new shape of data: (250000, 23)\n"
     ]
    }
   ],
   "source": [
    "y[np.nonzero(y == -1)] = 0\n",
    "Data = remove_features_with_too_many_missing_values(tX,0.66)\n",
    "Data = replace_missing_values_with_global_mean(Data)\n",
    "ZData = Z_score_of_each_feature(Data)\n",
    "\n",
    "trainx,trainy,validationx,validationy = split_data(ZData, y, 0.75, seed=1)\n",
    "#trainy = np.transpose(np.array(trainy,ndmin=2))\n",
    "\n",
    "trainx = np.delete(trainx, [3,6,22], axis=1)\n",
    "validationx = np.delete(validationx, [3,6,22], axis=1)\n",
    "trainyas = np.transpose(np.array(trainy,ndmin=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.149107e-01</td>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.407680</td>\n",
       "      <td>-0.469966</td>\n",
       "      <td>0.882478</td>\n",
       "      <td>1.033099</td>\n",
       "      <td>0.339894</td>\n",
       "      <td>0.170929</td>\n",
       "      <td>1.277084</td>\n",
       "      <td>-0.270811</td>\n",
       "      <td>0.846712</td>\n",
       "      <td>0.214212</td>\n",
       "      <td>0.225054</td>\n",
       "      <td>1.812288</td>\n",
       "      <td>-1.352820</td>\n",
       "      <td>-0.756757</td>\n",
       "      <td>-0.147267</td>\n",
       "      <td>0.386847</td>\n",
       "      <td>1.044402</td>\n",
       "      <td>-0.369921</td>\n",
       "      <td>1.557298e+00</td>\n",
       "      <td>3.248244e-01</td>\n",
       "      <td>0.412510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.408270e-01</td>\n",
       "      <td>0.552505</td>\n",
       "      <td>0.540136</td>\n",
       "      <td>-0.153167</td>\n",
       "      <td>1.404888</td>\n",
       "      <td>-0.756027</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>-0.661279</td>\n",
       "      <td>1.292164</td>\n",
       "      <td>0.147536</td>\n",
       "      <td>1.688504</td>\n",
       "      <td>-1.652849</td>\n",
       "      <td>-0.441526</td>\n",
       "      <td>0.411475</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>0.090798</td>\n",
       "      <td>-1.051683</td>\n",
       "      <td>-0.357719</td>\n",
       "      <td>0.021305</td>\n",
       "      <td>-0.821154</td>\n",
       "      <td>5.267049e-01</td>\n",
       "      <td>8.329932e-01</td>\n",
       "      <td>-0.273820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.388023e-16</td>\n",
       "      <td>3.195156</td>\n",
       "      <td>1.096560</td>\n",
       "      <td>-0.349710</td>\n",
       "      <td>0.989770</td>\n",
       "      <td>-0.430168</td>\n",
       "      <td>0.340361</td>\n",
       "      <td>2.768174</td>\n",
       "      <td>1.292164</td>\n",
       "      <td>-0.292406</td>\n",
       "      <td>-0.571650</td>\n",
       "      <td>-1.147554</td>\n",
       "      <td>3.387682</td>\n",
       "      <td>-0.737951</td>\n",
       "      <td>0.555132</td>\n",
       "      <td>0.382001</td>\n",
       "      <td>-1.200672</td>\n",
       "      <td>0.400135</td>\n",
       "      <td>0.021305</td>\n",
       "      <td>-0.863173</td>\n",
       "      <td>1.487145e+00</td>\n",
       "      <td>-1.434550e+00</td>\n",
       "      <td>-0.293970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.179442e-01</td>\n",
       "      <td>0.910379</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>-0.903016</td>\n",
       "      <td>1.196690</td>\n",
       "      <td>-0.830735</td>\n",
       "      <td>-0.712705</td>\n",
       "      <td>1.084818</td>\n",
       "      <td>-0.969095</td>\n",
       "      <td>-0.716598</td>\n",
       "      <td>-1.354138</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.301873</td>\n",
       "      <td>-0.397234</td>\n",
       "      <td>-1.730447</td>\n",
       "      <td>-0.323312</td>\n",
       "      <td>0.038692</td>\n",
       "      <td>-0.978149</td>\n",
       "      <td>-1.001792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003673e-17</td>\n",
       "      <td>1.111175e-17</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.023804e+00</td>\n",
       "      <td>-0.914556</td>\n",
       "      <td>1.313369</td>\n",
       "      <td>-0.651804</td>\n",
       "      <td>1.938794</td>\n",
       "      <td>-0.112795</td>\n",
       "      <td>-0.868143</td>\n",
       "      <td>-0.451747</td>\n",
       "      <td>-1.052877</td>\n",
       "      <td>-0.468428</td>\n",
       "      <td>-1.800568</td>\n",
       "      <td>-1.223513</td>\n",
       "      <td>-0.765298</td>\n",
       "      <td>0.646261</td>\n",
       "      <td>0.839728</td>\n",
       "      <td>-1.185429</td>\n",
       "      <td>-0.475042</td>\n",
       "      <td>-1.238475</td>\n",
       "      <td>-1.001792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003673e-17</td>\n",
       "      <td>1.111175e-17</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6.088086e-01</td>\n",
       "      <td>-1.009761</td>\n",
       "      <td>-0.539646</td>\n",
       "      <td>0.918192</td>\n",
       "      <td>-1.291464</td>\n",
       "      <td>1.917156</td>\n",
       "      <td>1.040948</td>\n",
       "      <td>-1.005763</td>\n",
       "      <td>0.508808</td>\n",
       "      <td>0.666766</td>\n",
       "      <td>0.314620</td>\n",
       "      <td>0.736020</td>\n",
       "      <td>-0.684128</td>\n",
       "      <td>-0.683404</td>\n",
       "      <td>0.998266</td>\n",
       "      <td>-0.029860</td>\n",
       "      <td>1.239982</td>\n",
       "      <td>0.577488</td>\n",
       "      <td>2.067499</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>-1.742045e+00</td>\n",
       "      <td>-4.559336e-01</td>\n",
       "      <td>1.230371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.098688e-01</td>\n",
       "      <td>-0.576543</td>\n",
       "      <td>0.651504</td>\n",
       "      <td>0.757735</td>\n",
       "      <td>0.725371</td>\n",
       "      <td>-0.735060</td>\n",
       "      <td>1.275085</td>\n",
       "      <td>2.288737</td>\n",
       "      <td>1.274570</td>\n",
       "      <td>-0.439827</td>\n",
       "      <td>0.925785</td>\n",
       "      <td>1.330485</td>\n",
       "      <td>2.292321</td>\n",
       "      <td>0.549027</td>\n",
       "      <td>-0.555730</td>\n",
       "      <td>-0.100206</td>\n",
       "      <td>-0.790677</td>\n",
       "      <td>0.666224</td>\n",
       "      <td>1.044402</td>\n",
       "      <td>0.812469</td>\n",
       "      <td>6.272329e-01</td>\n",
       "      <td>1.040816e+00</td>\n",
       "      <td>1.089751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.266844e-01</td>\n",
       "      <td>-1.098374</td>\n",
       "      <td>0.331435</td>\n",
       "      <td>-0.451288</td>\n",
       "      <td>0.669171</td>\n",
       "      <td>-0.780810</td>\n",
       "      <td>-0.175049</td>\n",
       "      <td>-1.269749</td>\n",
       "      <td>-0.985852</td>\n",
       "      <td>1.788886</td>\n",
       "      <td>0.547719</td>\n",
       "      <td>0.856014</td>\n",
       "      <td>-0.812160</td>\n",
       "      <td>0.415428</td>\n",
       "      <td>-0.765461</td>\n",
       "      <td>-0.591046</td>\n",
       "      <td>-0.966153</td>\n",
       "      <td>-0.177852</td>\n",
       "      <td>0.021305</td>\n",
       "      <td>-1.152798</td>\n",
       "      <td>-5.147361e-01</td>\n",
       "      <td>-1.218187e+00</td>\n",
       "      <td>-0.432856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.083335e-01</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>0.485126</td>\n",
       "      <td>-0.842157</td>\n",
       "      <td>0.678112</td>\n",
       "      <td>-0.656806</td>\n",
       "      <td>-0.804620</td>\n",
       "      <td>-0.902773</td>\n",
       "      <td>-1.036958</td>\n",
       "      <td>0.013412</td>\n",
       "      <td>2.013031</td>\n",
       "      <td>-1.389193</td>\n",
       "      <td>-0.921610</td>\n",
       "      <td>0.181432</td>\n",
       "      <td>1.013129</td>\n",
       "      <td>-0.119358</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>-0.632361</td>\n",
       "      <td>-1.001792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003673e-17</td>\n",
       "      <td>1.111175e-17</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.174312e-01</td>\n",
       "      <td>1.123253</td>\n",
       "      <td>-0.291707</td>\n",
       "      <td>2.128582</td>\n",
       "      <td>-0.975975</td>\n",
       "      <td>0.446346</td>\n",
       "      <td>0.835660</td>\n",
       "      <td>-0.992741</td>\n",
       "      <td>0.558239</td>\n",
       "      <td>0.711162</td>\n",
       "      <td>-1.253650</td>\n",
       "      <td>0.233477</td>\n",
       "      <td>-0.630786</td>\n",
       "      <td>-0.235176</td>\n",
       "      <td>-0.374073</td>\n",
       "      <td>2.765216</td>\n",
       "      <td>0.471863</td>\n",
       "      <td>0.671497</td>\n",
       "      <td>0.021305</td>\n",
       "      <td>1.764019</td>\n",
       "      <td>-1.998790e+00</td>\n",
       "      <td>-1.780446e+00</td>\n",
       "      <td>0.965872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-5.388023e-16</td>\n",
       "      <td>1.046835</td>\n",
       "      <td>-0.036494</td>\n",
       "      <td>-0.482204</td>\n",
       "      <td>-0.044833</td>\n",
       "      <td>0.371908</td>\n",
       "      <td>-0.662872</td>\n",
       "      <td>0.369806</td>\n",
       "      <td>-1.075498</td>\n",
       "      <td>-0.401098</td>\n",
       "      <td>-0.704261</td>\n",
       "      <td>1.588637</td>\n",
       "      <td>0.242729</td>\n",
       "      <td>0.115028</td>\n",
       "      <td>-0.732983</td>\n",
       "      <td>0.290587</td>\n",
       "      <td>0.385229</td>\n",
       "      <td>0.319218</td>\n",
       "      <td>-1.001792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003673e-17</td>\n",
       "      <td>1.111175e-17</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.348731e-01</td>\n",
       "      <td>-1.102108</td>\n",
       "      <td>-0.133974</td>\n",
       "      <td>-0.425414</td>\n",
       "      <td>0.657675</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>0.703264</td>\n",
       "      <td>-0.445828</td>\n",
       "      <td>1.250274</td>\n",
       "      <td>-0.121873</td>\n",
       "      <td>-0.541998</td>\n",
       "      <td>-0.183750</td>\n",
       "      <td>-0.383968</td>\n",
       "      <td>-0.115016</td>\n",
       "      <td>1.353323</td>\n",
       "      <td>-0.587702</td>\n",
       "      <td>1.190871</td>\n",
       "      <td>0.638342</td>\n",
       "      <td>2.067499</td>\n",
       "      <td>-0.171249</td>\n",
       "      <td>-5.689778e-01</td>\n",
       "      <td>2.244717e-01</td>\n",
       "      <td>0.944498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0   3.149107e-01  0.068332  0.407680 -0.469966  0.882478  1.033099  0.339894   \n",
       "1   7.408270e-01  0.552505  0.540136 -0.153167  1.404888 -0.756027 -0.287584   \n",
       "2  -5.388023e-16  3.195156  1.096560 -0.349710  0.989770 -0.430168  0.340361   \n",
       "3   4.179442e-01  0.910379 -0.005853 -0.903016  1.196690 -0.830735 -0.712705   \n",
       "4   1.023804e+00 -0.914556  1.313369 -0.651804  1.938794 -0.112795 -0.868143   \n",
       "5  -6.088086e-01 -1.009761 -0.539646  0.918192 -1.291464  1.917156  1.040948   \n",
       "6   5.098688e-01 -0.576543  0.651504  0.757735  0.725371 -0.735060  1.275085   \n",
       "7   6.266844e-01 -1.098374  0.331435 -0.451288  0.669171 -0.780810 -0.175049   \n",
       "8  -3.083335e-01  0.037323  0.485126 -0.842157  0.678112 -0.656806 -0.804620   \n",
       "9   1.174312e-01  1.123253 -0.291707  2.128582 -0.975975  0.446346  0.835660   \n",
       "10 -5.388023e-16  1.046835 -0.036494 -0.482204 -0.044833  0.371908 -0.662872   \n",
       "11 -1.348731e-01 -1.102108 -0.133974 -0.425414  0.657675  0.800400  0.703264   \n",
       "\n",
       "          7         8         9         10        11        12        13  \\\n",
       "0   0.170929  1.277084 -0.270811  0.846712  0.214212  0.225054  1.812288   \n",
       "1  -0.661279  1.292164  0.147536  1.688504 -1.652849 -0.441526  0.411475   \n",
       "2   2.768174  1.292164 -0.292406 -0.571650 -1.147554  3.387682 -0.737951   \n",
       "3   1.084818 -0.969095 -0.716598 -1.354138  0.010002  0.301873 -0.397234   \n",
       "4  -0.451747 -1.052877 -0.468428 -1.800568 -1.223513 -0.765298  0.646261   \n",
       "5  -1.005763  0.508808  0.666766  0.314620  0.736020 -0.684128 -0.683404   \n",
       "6   2.288737  1.274570 -0.439827  0.925785  1.330485  2.292321  0.549027   \n",
       "7  -1.269749 -0.985852  1.788886  0.547719  0.856014 -0.812160  0.415428   \n",
       "8  -0.902773 -1.036958  0.013412  2.013031 -1.389193 -0.921610  0.181432   \n",
       "9  -0.992741  0.558239  0.711162 -1.253650  0.233477 -0.630786 -0.235176   \n",
       "10  0.369806 -1.075498 -0.401098 -0.704261  1.588637  0.242729  0.115028   \n",
       "11 -0.445828  1.250274 -0.121873 -0.541998 -0.183750 -0.383968 -0.115016   \n",
       "\n",
       "          14        15        16        17        18        19            20  \\\n",
       "0  -1.352820 -0.756757 -0.147267  0.386847  1.044402 -0.369921  1.557298e+00   \n",
       "1   0.032730  0.090798 -1.051683 -0.357719  0.021305 -0.821154  5.267049e-01   \n",
       "2   0.555132  0.382001 -1.200672  0.400135  0.021305 -0.863173  1.487145e+00   \n",
       "3  -1.730447 -0.323312  0.038692 -0.978149 -1.001792  0.000000  1.003673e-17   \n",
       "4   0.839728 -1.185429 -0.475042 -1.238475 -1.001792  0.000000  1.003673e-17   \n",
       "5   0.998266 -0.029860  1.239982  0.577488  2.067499  0.121800 -1.742045e+00   \n",
       "6  -0.555730 -0.100206 -0.790677  0.666224  1.044402  0.812469  6.272329e-01   \n",
       "7  -0.765461 -0.591046 -0.966153 -0.177852  0.021305 -1.152798 -5.147361e-01   \n",
       "8   1.013129 -0.119358  0.018827 -0.632361 -1.001792  0.000000  1.003673e-17   \n",
       "9  -0.374073  2.765216  0.471863  0.671497  0.021305  1.764019 -1.998790e+00   \n",
       "10 -0.732983  0.290587  0.385229  0.319218 -1.001792  0.000000  1.003673e-17   \n",
       "11  1.353323 -0.587702  1.190871  0.638342  2.067499 -0.171249 -5.689778e-01   \n",
       "\n",
       "              21        22  \n",
       "0   3.248244e-01  0.412510  \n",
       "1   8.329932e-01 -0.273820  \n",
       "2  -1.434550e+00 -0.293970  \n",
       "3   1.111175e-17 -0.745439  \n",
       "4   1.111175e-17 -0.745439  \n",
       "5  -4.559336e-01  1.230371  \n",
       "6   1.040816e+00  1.089751  \n",
       "7  -1.218187e+00 -0.432856  \n",
       "8   1.111175e-17 -0.745439  \n",
       "9  -1.780446e+00  0.965872  \n",
       "10  1.111175e-17 -0.745439  \n",
       "11  2.244717e-01  0.944498  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualization\n",
    "Data_df = pd.DataFrame(ZData)\n",
    "Data_df.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signaldata = ZData[np.nonzero(y == 1)]\n",
    "nosignaldata = ZData[np.nonzero(y == -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'signaldata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-afb9ba2f8a25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignaldata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnosignaldata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'signaldata' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(ZData.shape[1]):\n",
    "    plt.figure\n",
    "    plt.hist(signaldata[:,i],100,color='b')\n",
    "    plt.hist(nosignaldata[:,i],100,color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x16cebb79e80>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cov = np.corrcoef(np.transpose(tX))\n",
    "plt.imshow(cov)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.6931471805599453\n",
      "Current iteration=100, loss=0.6803475817998539\n",
      "Current iteration=200, loss=0.6810763570309702\n",
      "Current iteration=300, loss=0.7064916609617319\n",
      "Current iteration=400, loss=0.5642065568984562\n",
      "Current iteration=500, loss=0.6783771661937044\n",
      "Current iteration=600, loss=0.6355543015087344\n",
      "Current iteration=700, loss=0.6368506049112387\n",
      "Current iteration=800, loss=0.5959076385252092\n",
      "Current iteration=900, loss=0.6817546205642259\n",
      "Current iteration=1000, loss=0.5859536602665699\n",
      "Current iteration=1100, loss=0.6111294766498331\n",
      "Current iteration=1200, loss=2.435868054025379\n",
      "Current iteration=1300, loss=0.6048186819281584\n",
      "Current iteration=1400, loss=0.6658177530486591\n",
      "Current iteration=1500, loss=0.4029822142870497\n",
      "Current iteration=1600, loss=0.6750275133824053\n",
      "Current iteration=1700, loss=0.5752353859742861\n",
      "Current iteration=1800, loss=0.6751671724533531\n",
      "Current iteration=1900, loss=0.806110195587542\n",
      "Current iteration=2000, loss=0.5571508200568881\n",
      "Current iteration=2100, loss=0.1638319718601305\n",
      "Current iteration=2200, loss=0.4269401574323545\n",
      "Current iteration=2300, loss=0.7567714515353423\n",
      "Current iteration=2400, loss=0.6425967031003395\n",
      "Current iteration=2500, loss=0.5020021862156937\n",
      "Current iteration=2600, loss=0.5279558945630537\n",
      "Current iteration=2700, loss=0.9159122564115103\n",
      "Current iteration=2800, loss=0.31055263214182793\n",
      "Current iteration=2900, loss=0.8347336293521412\n",
      "Current iteration=3000, loss=0.3924886011394355\n",
      "Current iteration=3100, loss=0.5329363986418391\n",
      "Current iteration=3200, loss=0.6761694645343893\n",
      "Current iteration=3300, loss=0.3248237585793475\n",
      "Current iteration=3400, loss=0.8348648365902887\n",
      "Current iteration=3500, loss=0.6219465134935658\n",
      "Current iteration=3600, loss=0.5297607404436779\n",
      "Current iteration=3700, loss=0.8471379147279532\n",
      "Current iteration=3800, loss=0.4615248646826262\n",
      "Current iteration=3900, loss=1.0330747464548922\n",
      "Current iteration=4000, loss=0.40811138540405417\n",
      "Current iteration=4100, loss=0.5349402871108142\n",
      "Current iteration=4200, loss=0.5456100130512876\n",
      "Current iteration=4300, loss=0.23617257803240926\n",
      "Current iteration=4400, loss=0.8068010801409039\n",
      "Current iteration=4500, loss=0.45329767739716964\n",
      "Current iteration=4600, loss=0.3971415092899551\n",
      "Current iteration=4700, loss=0.4722269369066894\n",
      "Current iteration=4800, loss=0.4002885612674516\n",
      "Current iteration=4900, loss=0.42624600261792966\n",
      "Current iteration=5000, loss=0.584203965017598\n",
      "Current iteration=5100, loss=0.5388004518012736\n",
      "Current iteration=5200, loss=0.7427880734248915\n",
      "Current iteration=5300, loss=0.433323111150308\n",
      "Current iteration=5400, loss=0.900295252187438\n",
      "Current iteration=5500, loss=0.4413133971859753\n",
      "Current iteration=5600, loss=13.113578295744603\n",
      "Current iteration=5700, loss=27.24449617455609\n",
      "Current iteration=5800, loss=0.8663872389769299\n",
      "Current iteration=5900, loss=0.3218164771786593\n",
      "Current iteration=6000, loss=0.3005236322030915\n",
      "Current iteration=6100, loss=0.07331466315948608\n",
      "Current iteration=6200, loss=0.4102045068900362\n",
      "Current iteration=6300, loss=0.28357619843713355\n",
      "Current iteration=6400, loss=0.8231167516792262\n",
      "Current iteration=6500, loss=0.7714008758333896\n",
      "Current iteration=6600, loss=0.4371798607983128\n",
      "Current iteration=6700, loss=0.3773071462132455\n",
      "Current iteration=6800, loss=0.39655360291422853\n",
      "Current iteration=6900, loss=0.3425745950555931\n",
      "Current iteration=7000, loss=0.6448131839035478\n",
      "Current iteration=7100, loss=0.7615137784682369\n",
      "Current iteration=7200, loss=0.37278813606951744\n",
      "Current iteration=7300, loss=0.3944505861477481\n",
      "Current iteration=7400, loss=1.8349661134045372\n",
      "Current iteration=7500, loss=0.7257028126406535\n",
      "Current iteration=7600, loss=0.32690547476873416\n",
      "Current iteration=7700, loss=1.3235206442405527\n",
      "Current iteration=7800, loss=0.629309379865686\n",
      "Current iteration=7900, loss=0.24208255576959267\n",
      "Current iteration=8000, loss=1.046308233795343\n",
      "Current iteration=8100, loss=1.0555038658537224\n",
      "Current iteration=8200, loss=0.34642748144659335\n",
      "Current iteration=8300, loss=0.9464232966405781\n",
      "Current iteration=8400, loss=0.8389411613605674\n",
      "Current iteration=8500, loss=1.126505790001222\n",
      "Current iteration=8600, loss=0.4405227643351413\n",
      "Current iteration=8700, loss=0.3567860692337887\n",
      "Current iteration=8800, loss=2.819889052866632\n",
      "Current iteration=8900, loss=8.94519746687689\n",
      "Current iteration=9000, loss=0.3522788149026278\n",
      "Current iteration=9100, loss=0.4939486779115965\n",
      "Current iteration=9200, loss=0.6641351790975619\n",
      "Current iteration=9300, loss=0.4994185616296226\n",
      "Current iteration=9400, loss=1.1125975793159761\n",
      "Current iteration=9500, loss=0.9525882619855004\n",
      "Current iteration=9600, loss=0.6272108291612184\n",
      "Current iteration=9700, loss=0.5382704106197711\n",
      "Current iteration=9800, loss=0.2540656920591331\n",
      "Current iteration=9900, loss=0.7689834611013584\n",
      "[0.737104]\n"
     ]
    }
   ],
   "source": [
    "degree = 3\n",
    "lambdas = [0]\n",
    "method = 'penalized'\n",
    "validationy[np.nonzero(validationy == 0)] = -1\n",
    "\n",
    "tx = build_poly(trainx, degree)\n",
    "validationtx = build_poly(validationx, degree)\n",
    "\n",
    "weight = np.zeros(tx.shape[1])\n",
    "accuracy = np.zeros(len(lambdas))\n",
    "\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "    loss, w = running_gradient(trainyas, tx, lambda_, method)\n",
    "    np.append(weight,w)\n",
    "    predictions = predict_labels(w, validationtx)\n",
    "    accuracy[ind] = calculate_classification_accuracy(validationy,predictions)\n",
    "    \n",
    "weights = w\n",
    "\n",
    "#plt.plot(lambdas,accuracy)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782224\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_labels(w, validationtx)\n",
    "\n",
    "accuracy = calculate_classification_accuracy(validationy,predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'C:/Users/joeld/Desktop/EPFL/machine learning/AIAIaie/data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test = remove_features_with_too_many_missing_values(tX_test,0.66)\n",
    "Data_test = replace_missing_values_with_global_mean(Data_test)\n",
    "ZData_test = Z_score_of_each_feature(Data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'C:/Users/joeld/Desktop/EPFL/machine learning/AIAIaie/data/output.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, ZData_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test implementations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.6931471805599453\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-509302a33af1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0minitial_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainyas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\machine learning\\AIAIaie\\scripts\\implementations.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[1;34m(y, tx, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m# get loss and update w using regularized logistic regression.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_by_penalized_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\machine learning\\AIAIaie\\scripts\\functions_for_implementations.py\u001b[0m in \u001b[0;36mlearning_by_penalized_gradient\u001b[1;34m(y, tx, w, gamma, lambda_, batch_size)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# ***************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;31m#calculate loss and gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpenalized_logistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;31m#update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\machine learning\\AIAIaie\\scripts\\functions_for_implementations.py\u001b[0m in \u001b[0;36mpenalized_logistic_regression\u001b[1;34m(y, tx, w, lambda_, batch_size)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;31m# ***************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;31m#calculate gradient using minibatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mminibatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_tx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_tx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_tx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\machine learning\\AIAIaie\\scripts\\functions_for_implementations.py\u001b[0m in \u001b[0;36mbatch_iter\u001b[1;34m(y, tx, batch_size, num_batches, shuffle)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mshuffle_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mshuffled_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mshuffle_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mshuffled_tx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mshuffle_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mshuffled_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "degree = 1\n",
    "lambda_ = 0.01\n",
    "\n",
    "validationy[np.nonzero(validationy == 0)] = -1\n",
    "max_iters = 1000\n",
    "gamma = 1e-4\n",
    "\n",
    "tx = build_poly(trainx, degree)\n",
    "validationtx = build_poly(validationx, degree)\n",
    "\n",
    "initial_w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "w, loss = reg_logistic_regression(trainyas, tx, lambda_ , initial_w, max_iters, gamma)\n",
    "\n",
    "print(w)\n",
    "predictions = predict_labels(w, validationtx)\n",
    "accuracy = calculate_classification_accuracy(validationy,predictions)\n",
    "    \n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
